{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2463764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technicalities\n",
    "\n",
    "import sys, os\n",
    "\n",
    "src = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "src = os.path.abspath(os.path.join(src, os.pardir))\n",
    "sys.path.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815fab9",
   "metadata": {},
   "source": [
    "# Notebook: Pipeline run demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b43b36",
   "metadata": {},
   "source": [
    "## Loading the problem of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c96cb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prc_challenge.problem import SupervisedRegression\n",
    "from prc_challenge.data import EmployeeSalary\n",
    "\n",
    "supervised_dataset = EmployeeSalary()\n",
    "problem = SupervisedRegression(supervised_dataset=supervised_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208136dd",
   "metadata": {},
   "source": [
    "## Defining a config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86535aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"cleaning\": [\n",
    "        \n",
    "    ],\n",
    "    \"feature_engineering\": [\n",
    "\n",
    "    ],\n",
    "    \"model\": [\"LinearRegression_v0_0_0\", supervised_dataset.features],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a516717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prc_challenge.utils.load_object_in_file import load_object_in_file\n",
    "\n",
    "loaded_config = {\n",
    "    \"cleaning\": [\n",
    "        load_object_in_file(\n",
    "            file_path=f\"../cleaning/__init__.py\", \n",
    "            namespace=\"cleaning\", \n",
    "            object_name=approach[0],\n",
    "        )(**approach[1]) for approach in config[\"cleaning\"]\n",
    "    ],\n",
    "    \"feature_engineering\": [\n",
    "        load_object_in_file(\n",
    "            file_path=f\"../feature_engineering/__init__.py\", \n",
    "            namespace=\"feature_engineering\", \n",
    "            object_name=approach[0],\n",
    "        )(**approach[1]) for approach in config[\"feature_engineering\"]\n",
    "    ],\n",
    "    \"model\": load_object_in_file(\n",
    "        file_path=f\"../model/__init__.py\", \n",
    "        namespace=\"model\", \n",
    "        object_name=config[\"model\"][0],\n",
    "    )(**config[\"model\"][1]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48b7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cleaning': [], 'feature_engineering': [], 'model': LinearRegression_v0_0_0()}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5944e4ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'feature_engineering_kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mproblem\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve_using\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/prc2025/repo/prc-challenge-2025/prc_challenge/problem/SupervisedRegression.py:47\u001b[39m, in \u001b[36mSupervisedRegression.solve_using\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m     45\u001b[39m train_X, train_Y = \u001b[38;5;28mself\u001b[39m.train_X, \u001b[38;5;28mself\u001b[39m.train_Y\n\u001b[32m     46\u001b[39m objects = load_objects_from_config(config)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m feature_engineering = objects[\u001b[33m\"\u001b[39m\u001b[33mfeature_engineering\u001b[39m\u001b[33m\"\u001b[39m](**\u001b[43mobjects\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeature_engineering_kwargs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     48\u001b[39m train_X = feature_engineering.fit_transform(X=train_X)\n\u001b[32m     50\u001b[39m model = objects[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m](**objects[\u001b[33m\"\u001b[39m\u001b[33mmodel_kwargs\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'feature_engineering_kwargs'"
     ]
    }
   ],
   "source": [
    "model = problem.solve_using(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0b4c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "This 'Pipeline' has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/enx/ec_concours/repo/prc-challenge-2025/.venv/lib/python3.13/site-packages/sklearn/utils/_available_if.py:32\u001b[39m, in \u001b[36m_AvailableIfDescriptor._check\u001b[39m\u001b[34m(self, obj, owner)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     check_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/enx/ec_concours/repo/prc-challenge-2025/.venv/lib/python3.13/site-packages/sklearn/pipeline.py:77\u001b[39m, in \u001b[36m_final_estimator_has.<locals>.check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'predict'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mproblem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/enx/ec_concours/repo/prc-challenge-2025/prc_challenge/problem/SupervisedRegression.py:32\u001b[39m, in \u001b[36mSupervisedRegression.evaluate\u001b[39m\u001b[34m(self, inference_pipeline)\u001b[39m\n\u001b[32m     29\u001b[39m metrics = {}\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Train MSE\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m y_pred = \u001b[43minference_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(\u001b[38;5;28mself\u001b[39m.train_X)\n\u001b[32m     33\u001b[39m y_true = \u001b[38;5;28mself\u001b[39m.train_Y\n\u001b[32m     34\u001b[39m metrics[\u001b[33m\"\u001b[39m\u001b[33mmse(train)\u001b[39m\u001b[33m\"\u001b[39m] = mean_squared_error(y_pred=y_pred, y_true=y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/enx/ec_concours/repo/prc-challenge-2025/.venv/lib/python3.13/site-packages/sklearn/utils/_available_if.py:43\u001b[39m, in \u001b[36m_AvailableIfDescriptor.__get__\u001b[39m\u001b[34m(self, obj, owner)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, owner=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[32m     42\u001b[39m         \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mowner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m         out = MethodType(\u001b[38;5;28mself\u001b[39m.fn, obj)\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;66;03m# This makes it possible to use the decorated method as an unbound method,\u001b[39;00m\n\u001b[32m     48\u001b[39m         \u001b[38;5;66;03m# for instance when monkeypatching.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/enx/ec_concours/repo/prc-challenge-2025/.venv/lib/python3.13/site-packages/sklearn/utils/_available_if.py:34\u001b[39m, in \u001b[36m_AvailableIfDescriptor._check\u001b[39m\u001b[34m(self, obj, owner)\u001b[39m\n\u001b[32m     32\u001b[39m     check_result = \u001b[38;5;28mself\u001b[39m.check(obj)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_result:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg)\n",
      "\u001b[31mAttributeError\u001b[39m: This 'Pipeline' has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "problem.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb2437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prc-challenge-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
